<html>
<head>
<title>Syzygy: Scene Graph Tutorial</title>
</head>
<body bgcolor="#ffffff">
<a href="index.html">Documentation Index</a>
<p><font size=+2>Syzygy: Scene Graph Tutorial</font>

<p>This tutorial will walk you through working with the Syzygy scene graph
from the Python prompt and introduce you to the concept of peer-to-peer
reality. To follow this tutorial, you'll need to either have 
compiled the <a href="GettingSoftware.html">szg library</a> and the Syzygy
<a href="PySZG.html">Python bindings</a> or have installed a Syzygy SDK as
appropriate for your system.

<p>This tutorial is complimentary to the <a href="SceneGraph.html">chapter</a>
describing a (deprecated) earlier scene graph API for Syzygy. That one can
still be used since it is built on the same framework described here.

<p><ul>
<li><a href="#Background">Basic Background on Scene Graphs</a>
<li><a href="#Database">Graphics Peers: Important Phleet Database Parameters</a>
<li><a href="#Peer">Graphics Peers: Tutorial Set Up</a>
<li><a href="#Points">Simple Points And Lines Example</a>
<li><a href="#Lighting">Scene Graph: Using Lights</a>
<li><a href="#Nodes">Scene Graph: Node Types</a>
<li><a href="#Meshes">Scene Graph: Built-in Meshes</a>
<li><a href="#Objects">Scene Graph: Loading Objects</a>
<li><a href="#File">Scene Graph: File Operations</a>
</ul>

<a name="Background">
<p><font size=+2>Basic Background on Scene Graphs</font>
</a>

<p>A Syzygy scene graph is a tree of nodes, each of which roughly corresponds
to an OpenGL primitive. A scene graph adds semantics and organization to plain
OpenGL. Nodes have names, allowing an external program to operate on the
graph by attaching to nodes with well-known names and manipulating them. The
hierarchical nature of scene graphs allows operations like saving either the
whole graph or a subtree, loading scene graphs and attaching them to nodes
in an existing scene graph, or removing whole graph subtrees.

<p>When drawing a Syzygy scene graph, the code traverses the tree in a depth
first search, changing the OpenGL state as it hits nodes. When all children
of a given node have been drawn, the state change it caused is undone. For
instance, when a transform node is hit, it places a transform matrix on the
OpenGL stack. Once all the transform node's children are hit, the transform
matrix is removed. Similarly, a material node changes the default color with
which triangles are rendered, with the scene graph remembering the previous
default color. Once all the material node's chidlren have rendered, the
default color switches back to what it was before the material node was
traversed.

<p>Most nodes only change the scene graph's state when traversed (or "drawn").
These include points, color, and index nodes, which correspond to state
variables in OpenGL vertex arrays. The drawable node is the only one which
actually produces geometry.

<a name="Database">
<p><font size=+2>Graphics Peers: Important Phleet Database Parameters</font>
</a>

<p>The graphics database requires a few Phleet parameters to be set for 
proper operation. For every computer upon which you want to run a display,
you should have

<pre>
  my_computer_name SZG_RENDER texture_path /the/textures/here
  my_computer_name SZG_RENDER text_path /the/text/bitmaps/here
</pre>

<p>Furthermore, it will be easier to load and save snapshots of graphics peers
if you set the SZG_PEER/path on each computer upon which you run a graphics
peer. Files will be automatically loaded and saved to this directory.

<pre>
  my_computer_name SZG_PEER path /the/peer/files/go/here
</pre>

<a name="Peer">
<p><font size=+2>Graphics Peers: Tutorial Set Up</font>
</a>

<p>This tutorial shows how to use the arGraphicsDatabase and its arGraphicsPeer
subclass from the Python prompt. If you want to be able to display your
work, you will want to use the arGraphicsPeer, so we focus on that.

<p>First, note that you must be running in Phleet mode, as explained in the
<a href="PhleetIntro.html">introductory</a> chapter of Syzygy's distributed
OS. Next, for connection brokering to work, you will have to be dlogin'ed
as the same Phleet user in each machine in your test environment.

<p>You will want to use the Python module rp.py (rp = reality peer). This
will provide you will some functionality needed to manipulate the system, and
it should be on your PYTHONPATH. It imports the Syzygy python bindings.
Start a Python prompt and then type:

<pre>
  from rp import *
  peer.setName("peer")
</pre>

The name "peer" must be unique in the Phleet across all graphics peers owned
by the Phleet user. Next,

<pre>
  peer.init({"peer_name"])
</pre>

The "peer_name" is simply a descriptive term used for this peer. If this
succeeds, you will see a "1" returned. Now type "dps()". You should see, among
other lines, something like:

<pre>
  smoke/peer_name/16
</pre>

Finally, you must do the following at the Python prompt:

<pre>
  peer.start()
</pre>

If it succeeds, it will return a "1".

<p>Now, you will start up a graphical "workspace" which can host a number of
graphics peers. This workspace can be run on any computer in your Phleet, but
beware that you must be dlogin'ed as the same Phleet user to connect. The
"workspace" must be given a name via the command line that is different from
any other workspace name used by that Phleet user.

<pre>
  szg-rp work1
</pre>

If all goes well, a graphics window will appear. You now need to create a peer
within your workspace and connect the two peers together. At the Python
prompt,

<pre>
  m = rpManager()
  work1 = m.getWorkspace("work1")
  handle = work1.newPeer("target")
</pre>

Please note that the name ("target") you give to the new peer must be unique
across all the peers you create as a particular Phleet user. If it isn't, the
final command will fail and you will see the following error message:

<pre>
  workspace error: peer failed to be created.
</pre>

The variable "handle" is a remote manipulation interface for the created
peer. It is of Python type rpPeer and has several methods that will be useful.

<pre>
  translate(x, y, z)

    Translates the peer within the workspace. This is useful for getting
    your content viewable by the workspace camera. This camera has the
    following characteristics:

    near clip plane, x extent = (-0.1, 0.1)
    near clip plane, y extent = (-0.1, 0.1)
    near/far clip plane distance = (0.2, 200)
    camera position = (0,5,20)
    pointed at = (0,5,0)
    up direction = (0,1,0)

  setComment(comment)

    Stores comment text in the remote peer.

  getComment()

    Retrieves comment text from the remote peer.

  reset()

    Clears the remote peer.
</pre>

Go ahead and put the display peer (in the remote workspace) in an easily
viewable spot. You will use the remote access handle.

<pre>
  handle.translate(0,5,-5)
</pre>

Finally, you will want to connect your peers, local and remote together, and
set data flowing between them. Use the local peer for this.

<pre>
  peer.connectToPeer("target")
</pre>

This returns the connection ID on success and -1 otherwise. Since this is
your first connection from "peer", you should see "0". By default, no
information flows on the connection between peers. Lets make the information
flow both ways.

<pre>
  peer.sending("target",1)
  peer.receiving("target",1)
</pre>

Upon success with each command, you should see a "1". You have just ensured
that updates to your local peer will be copied to the remote peer in the
workspace and vice versa. Please note that it is
possible to turn off sending or receiving of scene graph updates at any time
as above (passing "0" will turn it off). Please note that the connection is
referenced by the connected-to peer's name (in this case "target").

<p>The arGraphicsPeer has two other methods of particular importance. These
are useful when one of the peers that connect already has geometry.

<pre>
  arGraphicsPeer::pullSerial(remoteName, receive)

    Get the the description of the connected remote peer and put it into
    the local peer. If the receive flag is "1", continue receiving updates
    on the connection.

  arGraphicsPeer::pushSerial(remoteName, send)

    Push our own description to the connected remote peer. If the send
    flag is "1", continue sending updates.
</pre> 

<p>Now you can manipulate the scene graph contained in "peer" from the 
Python prompt and have the results appear in your workspace. Please note
that this section has just scratched the surface of all the fun things you
can do with reality peers.

<p><ul>
<li>You can have multiple peers embedded in each workspace. A common workspace
displayed on a projector might show the work of several users simultaneously.
<li>Instead of connecting to a peer in a workspace, you can connect to a
peer at someone else's Python command prompt. In this way, you can collaborate
it building an object.
<li>Two users can connect to the same peer in a workspace, collaborating that 
way.
</ul>

<a name="Points">
<p><font size=+2>Simple Points And Lines Example</font>
</a>

<p>We can now actually display some graphics. Recall that we used the
translate method of "handle" to position our remote peer within the
workspace so that (0,0,0) will be in the center of the display, with the
XY plane parallel to the screen.

<p>First, we will experiment with displaying some points. To display points,
we need three nodes: a points node (containing the positions), a colors
node containing different colors, and a drawable node telling us to draw
points. The graphics database (or graphics peer in our case) creates the
nodes. The factory function is passed the node's parent, its type, and finally
its name. The first node attaches to the graph's root. Since geometry and
color arrays are inherited state, they must be ancestors of the drawable node,
which needs them to make its points. Notice especially how each node is
a child of the one before it.

<pre>
  rt = peer.getRoot()
  p = peer.new(rt, "points", "points_node")
  c = peer.new(p, "color4", "colors_node")
  d = peer.new(c, "drawable", "drawable_node")
</pre>

Look at the scene graph structure by typing:

<pre>
  peer.printStructure()
</pre>

You'll see something like so:

<pre>
  Database structure:
    (0, "root", "root")
     (1, "points_node", "points")
      (2, "colors_node", "color4")
       (3, "drawable_node", "drawable")

</pre>

Now, you can actually get some points to display.

<pre>
  p.setPoints(4, [0,0,0, 1,0,0, 1,1,0, 0,1,0])
  c.setColor4(4, [1,1,1,1, 1,1,1,1, 1,1,1,1, 1,1,1,1])
  d.setDrawable(DG_POINTS, 4)
</pre>

The points node now contains the geometry for 4 points, listed one after
another. The color4 node now contains 4 color values (RGBA), listed one
after another. The drawable node asks that 4 points be drawn. These coordinates
for these points are taken, one after another, from the array stored in the
points node, and their colors are taken, in concert, one after another from
the the colors array stored in the color4 node. This is exactly the way
OpenGL vertex arrays work.

<p>We can even get fancy and change a only a particular point's coordinate.

<pre>
  p.setPoints(1, [0,0.5,0], [0])
</pre>

Here, the first parameter gives the number of points to change, the second
the coordinates, and the third the point IDs. We changed the first point in
the array. The same trick can be applied to color.

<pre>
  c.setColor4(1, [0,1,0,1], [1])
</pre>

Perhaps you would like to also display some lines between those points. We want
to share the points node, but not the color4 node.

<pre>
  cl = peer.new(p, "color4", "line_color")
  il = peer.new(cl, "index", "line_index")
  dl = peer.new(il, "drawable", "lines")
</pre>

You can print out the structure now and see your new nodes. There are two
branches to the tree, forking at the points node. Note how the children
of a node all are idented one from their parent.

<pre>
  (0, "root", "root")
   (1, "points_node", "points")
    (2, "colors_node", "color4")
     (3, "drawable_node", "drawable")
    (4, "line_color", "color4")
     (5, "line_index", "index")
      (6, "lines", "drawable")
</pre>

You can now define some lines. 2D and 3D drawables use an index node to
store the geometry they will use. Each such drawable has a stride, namely a
number of indices needed to define the next primitive. For a line set
(DG_LINES), this stride is 2. Each pair of indices gives the IDs of the points
in the line, one after another. The colors in the color4 node apply to
the lines, one after another.

<pre>
  cl.setColor4(6, [1,0,0,1, 1,0,0,1, 1,0,0,1, 1,0,0,1, 1,0,0,1, 1,0,0,1])
  il.setIndices(12, [0,1, 1,2, 2,3, 3,0, 0,2, 1,3])
  dl.setDrawable(DG_LINES, 6)
</pre>

The four points now define a box, with an "x" going through the middle.

<a name="Lighting">
<p><font size=+2>Scene Graph: Using Lights</font>
</a>

<p>Since many

<a name="Nodes">
<p><font size=+2>Scene Graph: Node Types</font>
</a>

<a name="Objects">
<p><font size=+2>Scene Graph: Loading Objects</font>
</a>

<p>Syzygy has a number of built-in shapes and the ability to load meshes in
the .obj and .3ds file formats. You can use these facilities to create a 
world by positioning, changing the colors, and changing the textures of
pre-made objects. 

<p>We assume that you have completed the basic section on 
<a href="#Peer">peers</a>, are working at the Python prompt, and that
"peer" and "handle" are as in that section. You will also need to have some
Phleet database variables set, as outlined <a href="#Database">here</a>.

<p>First, we will add some lights
to the scene, using a utility function from the "rp" module.

<pre>
  attachLights(peer)
</pre>

Now, add a sphere to the scene. This will start out simple, but gradually get
more complex, eventually encompassing ways to position the sphere and add
texture and color to it. Here, we make a sphere with 20 longitudinal and
latitudanal divisions (and 20x20x2=800 triangles). The sphere has radius 1
by default.

<pre>
  s = arSphereMesh(20)
</pre>

It will not appear yet in the scene graph. You have to attach it. The first
parameter is the sphere's unique name. The second parameter is the name of the
node we wish to attach it to.

<pre>
  s.attachMesh("sphere1","root")
</pre>

You will see a small white sphere, shaded by the lighting, in the center of
your screen. Unfortunately, we cannot do much with it. It cannot be moved and
its color cannot be changed. To do these things, we will have to start over.
To do this, we have to erase the sphere. This is done by getting the ID of the
sphere's top node and issuing the eraseNode method of arGraphicsPeer. To find
the node ID, try:

<pre>
  peer.printStructure()
</pre>

You see:

<pre>
(0, "root", "root")
 (1, "l0", "light")
 (2, "l1", "light")
 (3, "l2", "light")
 (4, "sphere1 points", "points")
  (5, "sphere1 indices", "index")
   (6, "sphere1 normal3", "normal3")
    (7, "sphere1 tex2", "tex2")
     (8, "sphere1 drawable", "drawable")
</pre>

And you want to delete all the nodes below "sphere1 points" (with ID 4) like
so:

<pre>
  peer.eraseNode(4)
</pre>

We want to be able to control the position and color of the sphere. To do
this, we create a transform node (attached to the scene graph root) and
a material node (attached to the transform node). Note how, in the factory
function, the parent node comes first, followed by the node type, and then
the node name. The sphere can be attached to the material node.

<pre>
  t1 = peer.new(peer.getRoot(), "transform", "transform1")
  m1 = peer.new(t1, "material", "material1")
</pre>

Perhaps we want a red sphere.

<pre>
  mater = m1.getMaterial()
  mater.diffuse = arVector3(1,0,0)
  m1.setMaterial(mater)
</pre>

Attach the sphere.

</pre>
  s.attachMesh("sphere1","material1")
</pre>

You can translate the sphere to coordinates (0,5,0) by:

<pre>
  t1.setTransform(ar_translationMatrix(0,5,0))
</pre>

You can translate and scale the sphere by:

<pre>
  t1.setTransform(ar_translationMatrix(0,-5,0)*ar_scaleMatrix(2,2,2))
</pre>

You can change the sphere color to yellow by:

<pre>
  mater.diffuse = arVector3(1,1,0)
  m1.setMaterial(mater)
</pre>

Instead, we could try a textured cube.

<pre>
  t2 = peer.new(peer.getRoot(), "transform", "transform2")
  tex = peer.new(t2, "texture", "texture2")
  tex.setFileName("wood.ppm")
</pre>

Attach the cube:

<pre>
  cube = arCubeMesh()
  cube.attachMesh("cube2","texture2")
</pre>

All texture files must live in the directory list given by the Phleet
parameter SZG_RENDER/texture_path. They must be either .ppm or .jpg in format
and must be square and have dimension a power of 2. You can turn the cube image
into a background by making the cube very large:

<pre>
  t2.setTransform(ar_scaleMatrix(100,100,100))
</pre>

Now, we will learn how to attach and edit models in .obj format. You are 
assumed to have unpacked the OBJ.tar distribution of model data to a directory
on your system, say /usr/local/OBJ. You can certainly put the models somewhere
else, but you will need to change the examples below accordingly.

<pre>
  al = arOBJ()
  t3 = peer.new(peer.getRoot(), "transform", "transform3")
  al.readOBJ("al.obj","/usr/local/OBJ")
</pre>

If the file is successfully read, readOBJ will return "1".

<pre>
  al.attachMesh("al","transform3")
</pre>

A little man should now appear in your scene. You can edit the figure's colors
like so:

<pre>
  mal = peer.find("al.default.colors3")
  mater = mal.getMaterial()
  mater.diffuse = arVector3(1,1,0)
  mal.setMaterial(mater)
</pre>

You can change other colors in the model as well. Their nodes are given by the
names: "al.default.colors1", "al.default.colors2", "al.default.colors3",
and "al.default.colors4".

<a name="File">
<p><font size=+2>Scene Graph: File Operations</font>
</a>

<hr>
</body>
</html>
